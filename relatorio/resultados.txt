1.
GRID_ROWS, GRID_COLS = 15, 5 (75)
Cell   0: 240 images
Cell   1: 8 images
Cell   5: 51 images
Cell   6: 113 images
Cell   7: 7 images
Cell  10: 70 images
Cell  11: 191 images
Cell  12: 82 images
Cell  15: 13 images
Cell  16: 47 images
Cell  17: 78 images
Cell  20: 36 images
Cell  21: 288 images
Cell  22: 330 images
Cell  25: 59 images
Cell  26: 386 images
Cell  27: 511 images
Cell  31: 142 images
Cell  32: 187 images
Cell  33: 8 images
Cell  35: 552 images
Cell  36: 646 images
Cell  37: 431 images
Cell  38: 95 images
Cell  40: 567 images
Cell  41: 560 images
Cell  42: 299 images
Cell  43: 162 images
Cell  46: 107 images
Cell  47: 213 images
Cell  48: 81 images
Cell  51: 148 images
Cell  52: 132 images
Cell  53: 168 images
Cell  54: 6 images
Cell  56: 138 images
Cell  57: 210 images
Cell  58: 373 images
Cell  59: 148 images
Cell  61: 96 images
Cell  62: 401 images
Cell  63: 411 images
Cell  64: 434 images
Cell  65: 81 images
Cell  66: 26 images
Cell  67: 125 images
Cell  68: 331 images
Cell  69: 219 images
Cell  70: 215 images
Cell  71: 10 images
Cell  73: 139 images

epoch     train_loss  valid_loss  accuracy  top_k_accuracy  time
0         5.750233    4.636654    0.015422  0.058795        12:48
1         5.721434    4.638364    0.017831  0.062651        13:12
2         5.721784    4.642076    0.020723  0.063614        12:47

#############################################
2. balanced_grid
Cell distribution:
Mean: 345.7, Std: 1.6
Cell  0: 346 samples, size: 0.0585° × 0.0867°
Cell  1: 346 samples, size: 0.0310° × 0.0967°
Cell  2: 346 samples, size: 0.0477° × 0.0680°
Cell  3: 346 samples, size: 0.0152° × 0.0834°
Cell  4: 346 samples, size: 0.0069° × 0.0876°
Cell  5: 346 samples, size: 0.0130° × 0.0840°
Cell  6: 346 samples, size: 0.0108° × 0.0720°
Cell  7: 346 samples, size: 0.0275° × 0.0901°
Cell  8: 346 samples, size: 0.0213° × 0.1646°
Cell  9: 346 samples, size: 0.0047° × 0.1629°
Cell 10: 346 samples, size: 0.0052° × 0.1789°
Cell 11: 346 samples, size: 0.0032° × 0.1794°
Cell 12: 346 samples, size: 0.0034° × 0.1836°
Cell 13: 346 samples, size: 0.0036° × 0.1859°
Cell 14: 346 samples, size: 0.0040° × 0.1782°
Cell 15: 346 samples, size: 0.0057° × 0.1820°
Cell 16: 346 samples, size: 0.0057° × 0.1874°
Cell 17: 346 samples, size: 0.0157° × 0.1888°
Cell 18: 346 samples, size: 0.0324° × 0.0984°
Cell 19: 346 samples, size: 0.0226° × 0.1178°
Cell 20: 346 samples, size: 0.0173° × 0.1410°
Cell 21: 346 samples, size: 0.0088° × 0.1397°
Cell 22: 346 samples, size: 0.0148° × 0.1556°
Cell 23: 346 samples, size: 0.0116° × 0.1708°
Cell 24: 346 samples, size: 0.0050° × 0.1654°
Cell 25: 346 samples, size: 0.0050° × 0.1624°
Cell 26: 346 samples, size: 0.0076° × 0.1386°
Cell 27: 346 samples, size: 0.0066° × 0.1967°
Cell 28: 346 samples, size: 0.0243° × 0.2019°
Cell 29: 337 samples, size: 0.0283° × 0.1991°

epoch     train_loss  valid_loss  accuracy  top_k_accuracy  time
0         5.103023    4.072146    0.032289  0.108434        13:18
1         5.101265    4.038980    0.035663  0.108434        13:22
2         5.098484    4.015220    0.040753  0.108434        13:45

#############################################
3. kmeans cells 30

Cell distribution:
Mean: 345.7, Std: 176.0
Cell  0: 232 samples, size: 0.0593° × 0.0344°
Cell  1: 299 samples, size: 0.0329° × 0.0332°
Cell  2: 472 samples, size: 0.0428° × 0.0362°
Cell  3: 391 samples, size: 0.0358° × 0.0196°
Cell  4: 140 samples, size: 0.0573° × 0.0550°
Cell  5: 192 samples, size: 0.0273° × 0.0245°
Cell  6: 425 samples, size: 0.0531° × 0.0331°
Cell  7: 283 samples, size: 0.0466° × 0.0318°
Cell  8: 232 samples, size: 0.0182° × 0.0244°
Cell  9: 319 samples, size: 0.0836° × 0.0269°
Cell 10: 479 samples, size: 0.0752° × 0.0363°
Cell 11: 346 samples, size: 0.0377° × 0.0309°
Cell 12: 636 samples, size: 0.0629° × 0.0241°
Cell 13: 272 samples, size: 0.0589° × 0.0284°
Cell 14: 697 samples, size: 0.0406° × 0.0314°
Cell 15: 175 samples, size: 0.0330° × 0.0262°
Cell 16: 675 samples, size: 0.0638° × 0.0322°
Cell 17: 523 samples, size: 0.0434° × 0.0317°
Cell 18: 629 samples, size: 0.0620° × 0.0325°
Cell 19: 351 samples, size: 0.0597° × 0.0386°
Cell 20: 129 samples, size: 0.0581° × 0.0270°
Cell 21:  88 samples, size: 0.0578° × 0.0165°
Cell 22: 262 samples, size: 0.0595° × 0.0345°
Cell 23: 166 samples, size: 0.0562° × 0.0243°
Cell 24: 348 samples, size: 0.0403° × 0.0285°
Cell 25: 116 samples, size: 0.0544° × 0.0361°
Cell 26: 237 samples, size: 0.0536° × 0.0357°
Cell 27: 226 samples, size: 0.0401° × 0.0295°
Cell 28: 459 samples, size: 0.0352° × 0.0229°
Cell 29: 572 samples, size: 0.0498° × 0.0246°

Training samples: 8296
Validation samples: 2075

Dataframe shape: (10371, 7)
Sample files exist: True
Unique cells: 30
Most common class: 557 samples
Least common class: 70 samples
Class imbalance ratio: 7.96

epoch     train_loss  valid_loss  accuracy  top_k_accuracy  time    
0         5.048744    4.054729    0.026988  0.107952        14:57
1         5.075758    4.085825    0.024096  0.100723        15:51
2         5.082394    4.050846    0.033253  0.097831        14:57

#############################################
4. efficient_net 512x512

epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	4.717434 	3.566653 	0.072771 	0.170120 	0.255904 	00:51
1 	4.403749 	3.399354 	0.106024 	0.220723 	0.316145 	00:51
2 	4.311409 	3.372981 	0.106988 	0.226506 	0.324337 	00:51

epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	4.281651 	3.359390 	0.109398 	0.231325 	0.333012 	01:01
1 	4.242167 	3.293112 	0.126265 	0.253976 	0.350843 	01:01
2 	4.153283 	3.266901 	0.126265 	0.263133 	0.364337 	01:01
3 	4.163126 	3.255740 	0.130602 	0.269398 	0.365301 	01:02
4 	4.097020 	3.241112 	0.132048 	0.272289 	0.373494 	01:01
5 	4.081868 	3.245979 	0.126265 	0.264096 	0.377349 	01:01

#############################################
5. same as 4, image transforms:
transforms = [
    *aug_transforms(
        size=IMG_CROP_SIZE,
        flip_vert=False,
        max_rotate=15.,
        max_zoom=1.05,
        max_lighting=0.3,
        max_warp=0.,
        p_affine=0.7,
        p_lighting=0.6
    ),
    Normalize.from_stats(*imagenet_stats)
]

epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	3.942222 	3.071672 	0.172530 	0.361928 	0.494458 	00:52
1 	2.985177 	2.396381 	0.299759 	0.546988 	0.683855 	00:52
2 	2.358287 	2.225491 	0.347470 	0.613976 	0.729639 	00:52

epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	2.160583 	2.081748 	0.395181 	0.645783 	0.755663 	01:02
1 	2.053930 	1.956468 	0.421687 	0.682892 	0.787952 	01:02
2 	1.583069 	1.709696 	0.500241 	0.733976 	0.826506 	01:02
3 	1.029485 	1.635405 	0.536386 	0.761446 	0.841446 	01:02
4 	0.574198 	1.565533 	0.566265 	0.777349 	0.854940 	01:02
5 	0.395452 	1.549101 	0.573976 	0.783133 	0.857349 	01:02

#############################################
6. resnet50 same as 5
epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	3.833169 	2.826161 	0.239518 	0.453494 	0.572530 	00:27
1 	2.925698 	2.441254 	0.301205 	0.532530 	0.662169 	00:27
2 	2.428705 	2.335587 	0.328675 	0.568675 	0.687229 	00:27

epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	2.167925 	2.252872 	0.364819 	0.608675 	0.720482 	00:31
1 	2.124921 	2.041496 	0.399036 	0.649639 	0.761446 	00:31
2 	1.733165 	1.872617 	0.463133 	0.700241 	0.800482 	00:31
3 	1.255986 	1.715681 	0.504578 	0.736867 	0.813976 	00:31
4 	0.870241 	1.609829 	0.524337 	0.751325 	0.839036 	00:31
5 	0.679175 	1.610012 	0.529157 	0.760000 	0.842410 	00:31

#############################################
7. convnext_base same as 6
epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	3.784887 	2.897388 	0.202892 	0.404819 	0.539277 	01:34
1 	3.011362 	2.448056 	0.295904 	0.523855 	0.661687 	01:34
2 	2.528441 	2.253183 	0.352771 	0.589880 	0.713253 	01:34

lr_min               lr_steep
0.003981071710586548 0.0006918309954926372
0.002290867641568184 0.001737800776027143

8. efficient_net lr 0.03981071710586548

1) training classifier head...
epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	3.848225 	3.090597 	0.120000 	0.280964 	0.414458 	00:50
1 	2.926950 	2.517921 	0.279036 	0.492530 	0.637108 	00:50
2 	2.525281 	2.301717 	0.318554 	0.569157 	0.694940 	00:51

2) fine-tuning entire model...
epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	2.371886 	2.281598 	0.329157 	0.579759 	0.706506 	01:01
1 	2.465140 	2.391822 	0.331084 	0.575904 	0.695904 	01:01
2 	2.380319 	2.270774 	0.352289 	0.603373 	0.704578 	01:01
3 	2.103693 	1.961805 	0.419759 	0.660241 	0.771566 	01:01
4 	1.695371 	1.720162 	0.495422 	0.741205 	0.829880 	01:01
5 	1.241397 	1.563803 	0.537831 	0.770602 	0.850602 	01:01
6 	0.809977 	1.517767 	0.569157 	0.800482 	0.870843 	01:01
7 	0.582364 	1.522754 	0.576867 	0.800482 	0.870361 	01:01

3) fine-tune with lower learning rate and higher weight decay
epoch 	train_loss 	valid_loss 	accuracy 	top_k_accuracy 	top_k_accuracy 	time
0 	0.578580 	1.626589 	0.561928 	0.789398 	0.868434 	01:01
1 	0.544645 	1.646858 	0.573494 	0.796627 	0.868434 	01:01
2 	0.421387 	1.662126 	0.583133 	0.799036 	0.876145 	01:00
3 	0.321823 	1.678852 	0.583133 	0.799518 	0.873253 	01:00